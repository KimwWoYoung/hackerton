{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 뉴스 제목으로 주가 예측\n",
        "1."
      ],
      "metadata": {
        "id": "hmE8ZbA9EdC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import reuters\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, Activation, Conv1D, MaxPooling1D, GlobalMaxPooling1D , Input\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score, roc_auc_score\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import re"
      ],
      "metadata": {
        "id": "m9RCnIbfNCkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PH-0GldYHyf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('stock_news_data_large.csv')"
      ],
      "metadata": {
        "id": "YYiszly1H3HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "nXgXJkAbKBn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(inputString):\n",
        "    text_rmv = re.sub('[+]','증가', inputString)\n",
        "    text_rmv = re.sub('[-]','감소', text_rmv)\n",
        "    text_rmv = re.sub('[↑▲]','상승', text_rmv)\n",
        "    text_rmv = re.sub('[↓△]','하락', text_rmv)\n",
        "\n",
        "    return text_rmv\n",
        ""
      ],
      "metadata": {
        "id": "Z-lsTIslR_gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['뉴스 제목'] = df['뉴스 제목'].apply(clean_text)"
      ],
      "metadata": {
        "id": "7obmPERASBiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # 괄호와 괄호 안에 있는 내용 삭제\n",
        "    text = re.sub(r'\\([^()]*\\)', '', text)  # () 안에 있는 내용 삭제\n",
        "    text = re.sub(r'\\[[^\\[\\]]*\\]', '', text)  # [] 안에 있는 내용 삭제\n",
        "    text = re.sub(r'\\{[^{}]*\\}', '', text)  # {} 안에 있는 내용 삭제\n",
        "\n",
        "    pattern_others = re.compile(r'\\.([^\\.]*(?:기자|특파원|교수|작가|대표|논설|고문|주필|부문장|팀장|장관|원장|연구원|이사장|위원|실장|차장|부장|에세이|화백|사설|소장|단장|과장|기획자|큐레이터|저작권|평론가|©|ⓒ|\\@|\\/|=|▶|무단|전재|재배포|금지|\\[|\\]|\\(\\))[^\\.]*)$')\n",
        "    text = pattern_others.sub('.', text)\n",
        "\n",
        "    # 특수문자 제거\n",
        "    text = re.sub(r'[^%.,+\\-\\w\\s]', ' ', text)  # 특수문자를 공백으로 대체\n",
        "\n",
        "    # 공백 제거\n",
        "    text = re.sub(r'\\s+', ' ', text)  # 연속된 공백을 하나의 공백으로 대체\n",
        "    text = text.strip()  # 문장 앞뒤의 공백 제거\n",
        "\n",
        "    # 연속된 줄바꿈을 하나의 줄바꿈으로 대체\n",
        "    text = re.sub(r'\\n+', '\\n', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def remove_stopwords(text, stopwords):\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word.lower() not in stopwords]\n",
        "    return ' '.join(words)\n",
        "\n",
        "stopwords = ['원본보기', '아이콘', 'AD', '자료', 'ADVERTISEMENT', 'Advertisement', 'viewer']\n",
        "\n",
        "# Preprocess text\n",
        "df['뉴스 제목'] = df['뉴스 제목'].apply(preprocess_text)\n",
        "\n",
        "# Apply stopword removal\n",
        "df['뉴스 제목'] = df['뉴스 제목'].apply(remove_stopwords, stopwords=stopwords)\n",
        "\n",
        "# Display the dataframe\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "IAvjzYDPS96_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "-5UQnTDqS5C-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"beomi/kcbert-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "tlCXSEzUM_9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df['뉴스 제목'].tolist()"
      ],
      "metadata": {
        "id": "GsrrsvKKNaBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_news = []\n",
        "for news in df['뉴스 제목']:\n",
        "    # 문장 토큰화 및 패딩\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        news,\n",
        "        add_special_tokens=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=300,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        embeddings = outputs.last_hidden_state.squeeze(0)\n",
        "        embedded_news.append(embeddings.tolist())\n",
        ""
      ],
      "metadata": {
        "id": "qY9GC0XhNgQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['kcbert_embedding'] = embedded_news"
      ],
      "metadata": {
        "id": "vzIJXaKbNnbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "DdFO0RF8ONuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result = pd.DataFrame()\n",
        "for i in range(len(df)):\n",
        "#     print(pd.DataFrame(list(X_train['dh_embedding_1'])[i]).T)\n",
        "\n",
        "    df_result= pd.concat([df_result, pd.DataFrame(list(df['kcbert_embedding'])[i]).T], ignore_index = True)"
      ],
      "metadata": {
        "id": "1tDYvhCYOVAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(list(df_result.iloc[0,:]))"
      ],
      "metadata": {
        "id": "rhzSdl1rO1G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result"
      ],
      "metadata": {
        "id": "sx-tqurTO6wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_3d = []\n",
        "\n",
        "for i in df.index :\n",
        "    tensor_date = []\n",
        "    tensor_date.append(list(df_result.iloc[i,:]))\n",
        "    tensor_3d.append(tensor_date)\n",
        "\n",
        "tensor_3d = np.array(tensor_3d)"
      ],
      "metadata": {
        "id": "WZUrlsMEO-1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "VVA6yQqDPCul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tensor_3d, df['주가_변동'], test_size = 0.2, random_state = 1, stratify = df['주가_변동'])"
      ],
      "metadata": {
        "id": "JvnMTxt9PHcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "id": "69vvzFOHPSYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.value_counts()"
      ],
      "metadata": {
        "id": "DilN927cPWYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "IKMgO2AfPYbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "model = tf.keras.Sequential([\n",
        "    layers.LSTM(100, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]),dropout=0.25),\n",
        "    layers.LSTM(100, return_sequences=True,dropout=0.25),\n",
        "    layers.LSTM(100, return_sequences=True,dropout=0.25),\n",
        "    layers.Bidirectional(layers.LSTM(100)),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "ks21EuIoPao-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))"
      ],
      "metadata": {
        "id": "5aU40LN6Pdcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_record = model.fit(X_train, y_train,\n",
        "                    epochs=30,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(X_train, y_train),\n",
        "                    shuffle=True)"
      ],
      "metadata": {
        "id": "QHP2vVWNPe9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_proba = model.predict(X_test)"
      ],
      "metadata": {
        "id": "JTDr6ueIPhEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(pred_proba)"
      ],
      "metadata": {
        "id": "Mp8Oc0oWPjHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.plot(training_record.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(training_record.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "fig.suptitle(\"Loss\")\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "RrOw40eIQQXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2차원인 pred_proba를 1차원으로 변경해준다 (1000,1)=>(1000)\n",
        "pred_proba_1d = pred_proba.reshape(-1)\n",
        "\n",
        "# 임계치 이상이면 True 미만이면 False를 부여한다.\n",
        "threshold = 0.43\n",
        "pred = (pred_proba_1d >= threshold)\n",
        ""
      ],
      "metadata": {
        "id": "8aU3KAWBPl6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the metrics\n",
        "accuracy_test_rnn= accuracy_score(y_test, pred)\n",
        "print(f'Accuracy: {accuracy_test_rnn}')\n",
        "#=> Accuracy: 0.988\n",
        "\n",
        "precision_test_rnn=precision_score(y_test, pred)\n",
        "print(f'Precision = {round(precision_test_rnn,3)}')\n",
        "#=> Precision = 0.99\n",
        "\n",
        "recall_test_rnn=recall_score(y_test, pred)\n",
        "print(f'Recall = {round(recall_test_rnn,3)}')\n",
        "#=> Recall = 0.99\n",
        "\n",
        "f1_test_rnn=f1_score(y_test, pred)\n",
        "print(f'f1 score = {round(f1_test_rnn,3)}')"
      ],
      "metadata": {
        "id": "3cnJtHUUPnt1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}